# Agreement Analysis Results

## Overall Metrics Across Rounds

| Metric | Round 1 | Round 2 | Round 3 |
|--------|---------|---------|---------|
| Mean Jaccard Similarity | 0.668 | 0.917 | 0.959 |
| Exact Agreement Rate | 0.569 | 0.888 | 0.940 |
| Mean Cohen's Kappa | 0.640 | 0.897 | 0.961 |

## Label-wise Agreement Rates

| Label | Round 1 | Round 2 | Round 3 |
|-------|---------|---------|---------|
| Label 1 | 0.830 | 0.952 | 0.971 |
| Label 2 | 0.863 | 0.979 | 0.994 |
| Label 3 | 0.925 | 0.988 | 0.996 |
| Label 4 | 0.942 | 0.983 | 0.992 |
| Label 5 | 0.894 | 0.971 | 0.986 |
| Label 6 | 0.899 | 0.986 | 0.994 |
| Label 7 | 0.971 | 0.994 | 0.996 |

## Label-wise Cohen's Kappa

| Label | Round 1 | Round 2 | Round 3 |
|-------|---------|---------|---------|
| Label 1 | 0.566 | 0.890 | 0.932 |
| Label 2 | 0.520 | 0.861 | 0.969 |
| Label 3 | 0.642 | 0.952 | 0.980 |
| Label 4 | 0.828 | 0.947 | 0.975 |
| Label 5 | 0.689 | 0.805 | 0.956 |
| Label 6 | 0.581 | 0.924 | 0.969 |
| Label 7 | 0.652 | 0.900 | 0.945 |