{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f291b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 16:33:25 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ce2e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 16:33:38 [config.py:689] This model supports multiple tasks: {'reward', 'embed', 'score', 'generate', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-19 16:33:39 [config.py:1713] Defaulting to use mp for distributed inference\n",
      "INFO 05-19 16:33:39 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-19 16:33:42 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='Qwen/Qwen3-235B-A22B', speculative_config=None, tokenizer='Qwen/Qwen3-235B-A22B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=8, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen3-235B-A22B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-19 16:33:42 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 05-19 16:33:42 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3, 4, 5, 6, 7], buffer_handle=(8, 10485760, 10, 'psm_92d7d4c4'), local_subscribe_addr='ipc:///tmp/262bcc40-9623-4eab-8172-4b32b8e53fa5', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:43 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc0cd0>\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:33:43 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fae5a30c'), local_subscribe_addr='ipc:///tmp/4c54c8cd-5c68-4a11-a583-57f742ba6e2b', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:45 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc0ed0>\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:33:45 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4f26dcda'), local_subscribe_addr='ipc:///tmp/26897680-1f03-4a94-8ec6-7e5080b21e6a', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:47 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc1210>\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:33:47 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7bd99460'), local_subscribe_addr='ipc:///tmp/bf3b6863-04e4-4112-8c24-c352a245aaf7', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:49 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc1910>\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:33:49 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_79e9be45'), local_subscribe_addr='ipc:///tmp/6e8f2780-81f4-4a65-9dc3-8149e6bb5bcd', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:52 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc1d10>\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:33:52 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e7718aa8'), local_subscribe_addr='ipc:///tmp/dbdf2b42-a34c-4fd5-9d15-893c3bb17e76', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:53 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc2190>\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:33:53 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a8c3a8e3'), local_subscribe_addr='ipc:///tmp/03880984-9b32-4097-91ea-ac23eed822b1', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:55 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc25d0>\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:33:55 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7c2dfce7'), local_subscribe_addr='ipc:///tmp/c079ed7f-f0a8-4543-9d46-cb63bee7cec9', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "WARNING 05-19 16:33:57 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e03fdfc2a10>\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:33:57 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_4a7fb539'), local_subscribe_addr='ipc:///tmp/a0dd3701-937a-4d39-97ca-cc77241f8dbe', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:33:59 [utils.py:993] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 05-19 16:33:59 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "INFO 05-19 16:34:03 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/duan/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3,4,5,6,7.json\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:03 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_4d41c39e'), local_subscribe_addr='ipc:///tmp/9395d3ac-c52b-493c-afa7-3921d5c4b5ca', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m \u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:34:03 [parallel_state.py:959] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 6\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 2\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 4\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 3\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 7\n",
      "INFO 05-19 16:34:03 [parallel_state.py:959] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 5\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:03 [parallel_state.py:959] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:04 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen3-235B-A22B...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m WARNING 05-19 16:34:05 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:34:05 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:06 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fe3ae7f2eb4fb8b6485db8739fef5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/118 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:34:43 [loader.py:458] Loading weights took 37.56 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:34:43 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 39.004332 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:34:43 [loader.py:458] Loading weights took 37.52 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:34:44 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 39.441541 seconds\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:34:44 [loader.py:458] Loading weights took 37.30 seconds\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:34:44 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 40.022105 seconds\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:34:44 [loader.py:458] Loading weights took 38.37 seconds\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:34:45 [loader.py:458] Loading weights took 39.42 seconds\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:34:45 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 40.805399 seconds\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:34:45 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 41.110422 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:45 [loader.py:458] Loading weights took 39.63 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:34:46 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 41.796685 seconds\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:34:46 [loader.py:458] Loading weights took 38.77 seconds\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:34:47 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 42.720776 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:47 [loader.py:458] Loading weights took 39.69 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:34:47 [gpu_model_runner.py:1291] Model loading took 54.9205 GiB and 43.378183 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_2_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:426] Dynamo bytecode transform time: 25.79 s\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_6_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:426] Dynamo bytecode transform time: 26.02 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_0_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:426] Dynamo bytecode transform time: 26.04 s\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_5_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:35:13 [backends.py:426] Dynamo bytecode transform time: 26.04 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_1_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:426] Dynamo bytecode transform time: 26.16 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_3_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:426] Dynamo bytecode transform time: 26.21 s\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_7_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:426] Dynamo bytecode transform time: 26.24 s\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:416] Using cache directory: /home/duan/.cache/vllm/torch_compile_cache/d7f44fa65a/rank_4_0 for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:35:14 [backends.py:426] Dynamo bytecode transform time: 26.42 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:35:16 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m \u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "WARNING 05-19 16:35:40 [fused_moe.py:670] Using default MoE config. Performance might be sub-optimal! Config file not found at /home/duan/miniconda3/envs/copylookup/lib/python3.11/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m \u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m \u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.24 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.21 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.02 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.04 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 25.79 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.16 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.04 s in total\n",
      "INFO 05-19 16:35:40 [monitor.py:33] torch.compile takes 26.42 s in total\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 255,408 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 7.79x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 202,208 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 6.17x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 215,056 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 6.56x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 195,088 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 5.95x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 276,096 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 8.43x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 276,096 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 8.43x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 276,096 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 8.43x\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:634] GPU KV cache size: 104,288 tokens\n",
      "INFO 05-19 16:35:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 3.18x\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:36:33 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m INFO 05-19 16:36:33 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m INFO 05-19 16:36:34 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:36:34 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:36:34 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:36:34 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:36:34 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:36:35 [custom_all_reduce.py:195] Registering 12663 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=7 pid=799891)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=799657)\u001b[0;0m \u001b[1;36m(VllmWorker rank=6 pid=799817)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "\u001b[1;36m(VllmWorker rank=4 pid=799715)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=799615)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "\u001b[1;36m(VllmWorker rank=5 pid=799761)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.94 GiB\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=799515)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.93 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=799561)\u001b[0;0m INFO 05-19 16:36:36 [gpu_model_runner.py:1626] Graph capturing finished in 51 secs, took 1.93 GiB\n",
      "INFO 05-19 16:36:36 [core.py:163] init engine (profile, create kv cache, warmup model) took 108.34 seconds\n",
      "INFO 05-19 16:36:36 [core_client.py:435] Core engine process 0 ready.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Qwen/Qwen3-235B-A22B\" #\"Qwen/Qwen3-235B-A22B\" #\"Qwen/Qwen3-8B\"\n",
    "tensor_parallel_size = 8 if model_path==\"Qwen/Qwen3-235B-A22B\" else 1\n",
    "llm = LLM(model_path, tensor_parallel_size=tensor_parallel_size, max_model_len=32768)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba3849",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a6fdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"## Multi-Label Analysis of \"Local\" Identity Definition Standards in Social Network Texts\n",
    "\n",
    "### 1. Task Objective\n",
    "\n",
    "Analyze the given social media text segment to identify the prominent standards that the **author themself** explicitly expresses agreement with, or **implicitly agrees with** through the subtext, for defining a **\"local person\" (or its synonyms)**. Based on the Recognition Logic (RL) framework in this manual, output all corresponding RL category labels. A text segment may correspond to **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local person\" identity. If the text merely discusses wealth, social status, quality of life, property advantages/disadvantages, job quality, etc., **without explicitly or strongly implying** that these are standards used to judge whether someone is a \"local person,\" then **do not annotate**.\n",
    "\n",
    "### 2. Core Principles\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core viewpoint, claim, or evaluation regarding the definition of \"local person\" identity as presented by the **speaker (i.e., the text author)**. Understanding **what the author intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of Recognition Logic:** The identified recognition logic elements are not just isolated features; understand the **functional role** they play in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** Actively perform contextual reasoning to understand the basis of legitimacy for \"local person\" identity or the evaluation criteria endorsed by the author behind their discourse.\n",
    "*   **Exclude Resisted Standards and Irrelevant Discussions:** For standards that the author explicitly expresses resistance to, denies, or merely describes as being used against them by others, **do not annotate**. For discussions not directly related to defining \"local person\" identity, **do not annotate**.\n",
    "\n",
    "### 3. Recognition Logic Framework\n",
    "\n",
    "**Uniform Sentence Template:**\n",
    "The author believes that people (or the author themself) should/often/can use the logic or standards represented by [Recognition Logic Type] to define who is/is not a 'local person', or to evaluate the quality/scope of a 'local' area.\n",
    "\n",
    "**Recognition Logic Type Definitions and Features:**\n",
    "\n",
    "#### Recognition Logic 1 (RL1): Vernacular Spatial Authority\n",
    "*   **Definition:** Shared, habitual, or historically sedimented local perceptions of intra-city spatial categories that the author endorses or describes. These perceptions are not based on official administrative boundaries but reflect collective emotional maps, used as cultural shorthand for assigning evaluative or symbolic labels.\n",
    "*   **Core Identifying Features:**\n",
    "    *   The author explicitly proposes or assumes a logic for classifying **which areas \"count\" or \"do not count\" as core local areas, or which areas have identity or cognitive differences** (e.g., \"Outside the Third Ring Road is not considered Chengdu\").\n",
    "    *   The author implies the status of a specific area within the \"local\" identity system by describing its **symbolic meaning, historical labels, or common societal views (collective emotional map)**.\n",
    "    *   The author discusses **the social recognition changes or current consensus on concepts like \"urban area scope,\" \"city boundaries,\" etc.**\n",
    "\n",
    "#### Recognition Logic 2 (RL2): Administrative Legitimacy\n",
    "*   **Definition:** Appeals to official jurisdiction, legal status, or administrative designation. Speakers in this category justify inclusion or exclusion based on hukou registration (a household registration system), district incorporation, or municipal redistricting.\n",
    "*   **Core Identifying Features:** Keywords include \"administrative division,\" \"incorporated into,\" \"belongs to,\" \"where is the hukou from,\" \"ID card prefix,\" etc., used as a basis for judging whether a person/place is administratively/legally \"local.\"\n",
    "\n",
    "#### Recognition Logic 3 (RL3): Family Rootedness (Family Historical Roots / Individual Growth History)\n",
    "*   **Definition:** The author endorses or cites the evaluation of local legitimacy based on the generational depth of family settlement. Claims in this category emphasize lineage, ancestry, or long-term familial ties to the area.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Emphasizes terms like \"**born and raised locally**,\" \"**generations**,\" \"**ancestors**,\" \"**parents' generation**,\" \"**within three generations**,\" \"**came since childhood/kindergarten**,\" etc., to prove someone is a \"genuine local\" or has formed the basis of a \"local person's\" identity.\n",
    "    *   Describes identity differences due to migration history (or lack thereof).\n",
    "\n",
    "#### Recognition Logic 4 (RL4): Linguistic-Cultural Recognition\n",
    "*   **Definition:** Relies on dialect, accent, or cultural linguistic habits as a boundary marker. Regional speech features are treated as proxies for insider status, and deviations often provoke mockery or mistrust. May also include identification with specific local cultural habits (e.g., customs, lifestyle).\n",
    "*   **Core Identifying Features:** Mentions \"speaking the local dialect,\" \"accent,\" \"cannot understand/stand certain accents,\" \"don't you understand our local rules,\" etc., as criteria for distinguishing insiders from outsiders, or judging if someone is \"one of us\" or possesses \"local attributes.\"\n",
    "\n",
    "#### Recognition Logic 5 (RL5): Functional Livability (Convenience of Living Functions and Environmental Quality Perception)\n",
    "*   **Definition:** The author endorses or cites the evaluation of urban areas in terms of their material infrastructure (e.g., transit, housing, education, or access to services), often to assert spatial superiority or desirability.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"subway,\" \"amenities,\" \"convenience,\" \"education,\" \"good greening,\" \"few people,\" \"streetscape,\" \"comfortable,\" etc., and **directly associates these with an evaluation of whether an area is \"good,\" \"livable,\" or \"worth living in.\"**\n",
    "    *   The author considers an area an ideal \"local\" living space due to its RL5 characteristics, or believes an area does not meet the standard of a \"good local\" area due to a lack of RL5 characteristics.\n",
    "\n",
    "#### Recognition Logic 6 (RL6): Social Embeddedness (Depth of Social Roots and Symbolism of Economic Status)\n",
    "*   **Definition:** The author endorses or cites judging whether someone is a local based on their integration into local social circles and possession of local fixed assets. This includes community resources (like dividends, familiarity with the community) and material or symbolic resources, such as (inherited) property.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"connections (renmai),\" \"dividends,\" \"old relationships,\" \"community influence,\" \"friends nearby,\" \"has several properties in the city center,\" \"impact of high/low housing prices on identity,\" \"spending one or two million to buy a house,\" etc., and **explicitly or implicitly links these to the \"stability, authenticity, hierarchy of local identity, or evaluation criteria for a region.\"**\n",
    "\n",
    "#### Recognition Logic 7 (RL7): Occupational Typification\n",
    "*   **Definition:** The author endorses or cites framing identity by associating certain districts with dominant professional groups, such as civil servants, migrant workers, or business owners, thereby invoking implicit hierarchies of class and worth.\n",
    "*   **Core Identifying Features:** Mentions specific occupations or types of people (e.g., \"farmers,\" \"those who farm,\" \"migrant workers\"), and **strongly associates them with the \"local attributes,\" resident composition, or social stratification of a specific area**, thereby defining identity or evaluating the area.\n",
    "\n",
    "### 4. Annotation Procedure\n",
    "1.  **Step 1: Identify named entities mentioned in the text**\n",
    "    *   Read through the text and record the entities mentioned.\n",
    "2.  **Step 2: Match arguments to each named entity**\n",
    "    *   Read the text carefully and match the corresponding viewpoint statements to each mentioned entity.\n",
    "3.  **Step 3: Analyze the underlying recognition logic behind each viewpoint statement**\n",
    "    *   For each entity, analyze which recognition logic(s) the speaker's expressed viewpoint (if any) is based on. It can be multiple recognition logics.\n",
    "4.  **Step 4: Output the results**\n",
    "    *   Output all matched **one or more** recognition logic category labels [Recognition Logic N], separated by ``, `` (a comma followed by a space).\n",
    "\n",
    "### 5. Important Notes\n",
    "*   Constantly remind yourself that the annotation target is **standards that the author themself does not explicitly oppose and uses to define \"local person\" identity or evaluate a \"local\" area, and understand their function in the author's core argument.**\n",
    "*   Do not rely solely on keyword matching; deeply understand the logic, intent, and core viewpoint behind the author's discourse. **Follow the steps from Step 1 to Step 4 in 4. Annotation Procedure; do not skip steps.**\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they use these standards to define \"who is a local person\" or evaluate \"the quality/scope/distinction of a local area,\" then **do not annotate.**\n",
    "*   Output the result after the `Output: ` marker. **Stop immediately** after outputting the result; do not output any further content.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910dcf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6277f12d53dd415db5f95568361c72ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61730611166347f0bd1d73e0ef1d1924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b743d1b0d154cfdb08c9ce8b18680ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5c6f55d7bf4a6abba95c5d1cbb97f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca8f215e5d43a0a042a9e3caab0792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/83 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sample.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "all_outputs = []\n",
    "batch_size = 100\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.8, top_k=20, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        ) + \"**Step 1: Understand the Author's Core Expressive Intent**\\n \"\n",
    "        formatted_prompts_batch.append(formatted_prompt)\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832d36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Extracted label was empty after stripping wrappers for original text at index 8 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 11 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 39 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 57 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 76 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 99 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 100 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 115 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 122 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 129 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 130 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 133 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 139 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 141 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 144 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 148 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 149 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 168 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 190 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 206 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 239 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 240 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 242 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 247 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 251 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 270 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 273 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 298 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 325 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 395 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 405 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 418 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 419 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 425 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 438 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Successfully processed 483 model outputs.\n",
      "Results saved to Qwen3-235B-A22B_zero_shot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text         RL_Types  \\\n",
      "0   ...            RL1**   \n",
      "1  ...  RL1, RL3, RL4   \n",
      "2  ...           ** RL4   \n",
      "3  ...        RL1, RL3   \n",
      "4  ...     ** RL1, RL4   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0   The author is expressing pride and optimism a...  \n",
      "1   The author is expressing frustration and obse...  \n",
      "2   The author is sharing a personal experience o...  \n",
      "3   *   The author is expressing frustration and ...  \n",
      "4   The author is criticizing certain attitudes a...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"Output: \"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"results/{model_path.split('/')[-1]}_zero_shot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed41daf",
   "metadata": {},
   "source": [
    "# Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8794c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"## Multi-Label Analysis of \"Local\" Identity Definition Standards in Social Network Texts\n",
    "\n",
    "### 1. Task Objective\n",
    "\n",
    "Analyze the given social media text segment to identify the prominent standards that the **author themself** explicitly expresses agreement with, or **implicitly agrees with** through the subtext, for defining a **\"local person\" (or its synonyms)**. Based on the Recognition Logic (RL) framework in this manual, output all corresponding RL category labels. A text segment may correspond to **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local person\" identity. If the text merely discusses wealth, social status, quality of life, property advantages/disadvantages, job quality, etc., **without explicitly or strongly implying** that these are standards used to judge whether someone is a \"local person,\" then **do not annotate**.\n",
    "\n",
    "### 2. Core Principles\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core viewpoint, claim, or evaluation regarding the definition of \"local person\" identity as presented by the **speaker (i.e., the text author)**. Understanding **what the author intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of Recognition Logic:** The identified recognition logic elements are not just isolated features; understand the **functional role** they play in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** Actively perform contextual reasoning to understand the basis of legitimacy for \"local person\" identity or the evaluation criteria endorsed by the author behind their discourse.\n",
    "*   **Exclude Resisted Standards and Irrelevant Discussions:** For standards that the author explicitly expresses resistance to, denies, or merely describes as being used against them by others, **do not annotate**. For discussions not directly related to defining \"local person\" identity, **do not annotate**.\n",
    "\n",
    "### 3. Recognition Logic Framework\n",
    "\n",
    "**Uniform Sentence Template:**\n",
    "The author believes that people (or the author themself) should/often/can use the logic or standards represented by [Recognition Logic Type] to define who is/is not a 'local person', or to evaluate the quality/scope of a 'local' area.\n",
    "\n",
    "**Recognition Logic Type Definitions and Features:**\n",
    "\n",
    "#### Recognition Logic 1 (RL1): Vernacular Spatial Authority\n",
    "*   **Definition:** Shared, habitual, or historically sedimented local perceptions of intra-city spatial categories that the author endorses or describes. These perceptions are not based on official administrative boundaries but reflect collective emotional maps, used as cultural shorthand for assigning evaluative or symbolic labels.\n",
    "*   **Core Identifying Features:**\n",
    "    *   The author explicitly proposes or assumes a logic for classifying **which areas \"count\" or \"do not count\" as core local areas, or which areas have identity or cognitive differences** (e.g., \"Outside the Third Ring Road is not considered Chengdu\").\n",
    "    *   The author implies the status of a specific area within the \"local\" identity system by describing its **symbolic meaning, historical labels, or common societal views (collective emotional map)**.\n",
    "    *   The author discusses **the social recognition changes or current consensus on concepts like \"urban area scope,\" \"city boundaries,\" etc.**\n",
    "\n",
    "#### Recognition Logic 2 (RL2): Administrative Legitimacy\n",
    "*   **Definition:** Appeals to official jurisdiction, legal status, or administrative designation. Speakers in this category justify inclusion or exclusion based on hukou registration (a household registration system), district incorporation, or municipal redistricting.\n",
    "*   **Core Identifying Features:** Keywords include \"administrative division,\" \"incorporated into,\" \"belongs to,\" \"where is the hukou from,\" \"ID card prefix,\" etc., used as a basis for judging whether a person/place is administratively/legally \"local.\"\n",
    "\n",
    "#### Recognition Logic 3 (RL3): Family Rootedness (Family Historical Roots / Individual Growth History)\n",
    "*   **Definition:** The author endorses or cites the evaluation of local legitimacy based on the generational depth of family settlement. Claims in this category emphasize lineage, ancestry, or long-term familial ties to the area.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Emphasizes terms like \"**born and raised locally**,\" \"**generations**,\" \"**ancestors**,\" \"**parents' generation**,\" \"**within three generations**,\" \"**came since childhood/kindergarten**,\" etc., to prove someone is a \"genuine local\" or has formed the basis of a \"local person's\" identity.\n",
    "    *   Describes identity differences due to migration history (or lack thereof).\n",
    "\n",
    "#### Recognition Logic 4 (RL4): Linguistic-Cultural Recognition\n",
    "*   **Definition:** Relies on dialect, accent, or cultural linguistic habits as a boundary marker. Regional speech features are treated as proxies for insider status, and deviations often provoke mockery or mistrust. May also include identification with specific local cultural habits (e.g., customs, lifestyle).\n",
    "*   **Core Identifying Features:** Mentions \"speaking the local dialect,\" \"accent,\" \"cannot understand/stand certain accents,\" \"don't you understand our local rules,\" etc., as criteria for distinguishing insiders from outsiders, or judging if someone is \"one of us\" or possesses \"local attributes.\"\n",
    "\n",
    "#### Recognition Logic 5 (RL5): Functional Livability (Convenience of Living Functions and Environmental Quality Perception)\n",
    "*   **Definition:** The author endorses or cites the evaluation of urban areas in terms of their material infrastructure (e.g., transit, housing, education, or access to services), often to assert spatial superiority or desirability.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"subway,\" \"amenities,\" \"convenience,\" \"education,\" \"good greening,\" \"few people,\" \"streetscape,\" \"comfortable,\" etc., and **directly associates these with an evaluation of whether an area is \"good,\" \"livable,\" or \"worth living in.\"**\n",
    "    *   The author considers an area an ideal \"local\" living space due to its RL5 characteristics, or believes an area does not meet the standard of a \"good local\" area due to a lack of RL5 characteristics.\n",
    "\n",
    "#### Recognition Logic 6 (RL6): Social Embeddedness (Depth of Social Roots and Symbolism of Economic Status)\n",
    "*   **Definition:** The author endorses or cites judging whether someone is a local based on their integration into local social circles and possession of local fixed assets. This includes community resources (like dividends, familiarity with the community) and material or symbolic resources, such as (inherited) property.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"connections (renmai),\" \"dividends,\" \"old relationships,\" \"community influence,\" \"friends nearby,\" \"has several properties in the city center,\" \"impact of high/low housing prices on identity,\" \"spending one or two million to buy a house,\" etc., and **explicitly or implicitly links these to the \"stability, authenticity, hierarchy of local identity, or evaluation criteria for a region.\"**\n",
    "\n",
    "#### Recognition Logic 7 (RL7): Occupational Typification\n",
    "*   **Definition:** The author endorses or cites framing identity by associating certain districts with dominant professional groups, such as civil servants, migrant workers, or business owners, thereby invoking implicit hierarchies of class and worth.\n",
    "*   **Core Identifying Features:** Mentions specific occupations or types of people (e.g., \"farmers,\" \"those who farm,\" \"migrant workers\"), and **strongly associates them with the \"local attributes,\" resident composition, or social stratification of a specific area**, thereby defining identity or evaluating the area.\n",
    "\n",
    "### 4. Annotation Procedure\n",
    "1.  **Step 1: Identify named entities mentioned in the text**\n",
    "    *   Read through the text and record the entities mentioned.\n",
    "2.  **Step 2: Match arguments to each named entity**\n",
    "    *   Read the text carefully and match the corresponding viewpoint statements to each mentioned entity.\n",
    "3.  **Step 3: Analyze the underlying recognition logic behind each viewpoint statement**\n",
    "    *   For each entity, analyze which recognition logic(s) the speaker's expressed viewpoint (if any) is based on. It can be multiple recognition logics.\n",
    "4.  **Step 4: Output the results**\n",
    "    *   Output all matched **one or more** recognition logic category labels [Recognition Logic N], separated by ``, `` (a comma followed by a space).\n",
    "\n",
    "### 5. Important Notes\n",
    "*   Constantly remind yourself that the annotation target is **standards that the author themself does not explicitly oppose and uses to define \"local person\" identity or evaluate a \"local\" area, and understand their function in the author's core argument.**\n",
    "*   Do not rely solely on keyword matching; deeply understand the logic, intent, and core viewpoint behind the author's discourse. **Follow the steps from Step 1 to Step 4 in 4. Annotation Procedure; do not skip steps.**\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they use these standards to define \"who is a local person\" or evaluate \"the quality/scope/distinction of a local area,\" then **do not annotate.**\n",
    "*   Output the result after the `Output: ` marker. **Stop immediately** after outputting the result; do not output any further content.\n",
    "\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 1 (RL1)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Well, people from Chongzhou, when asked where they're from, they directly say Chongzhou, not Chengdu. What I've learned since I was young is that Chengdu people generally think areas outside the Third Ring Road don't count as Chengdu.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author wants to express that they and people around them, when identifying their \"local\" identity, will directly say \"Chongzhou\" and not \"Chengdu\"; furthermore, the author has been influenced by a long-standing social convention since childhood that Chengdu people generally believe areas outside the city's Third Ring Road are not considered part of the core \"Chengdu\" local area. This reflects a standard for defining \"local people\" based on geographical scope and social custom.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- People around the author identify their area as \"Chongzhou\", not \"Chengdu\", reflecting regional cognition and identity definition.\n",
    "- \"Learned since I was young\" (ear) indicates this cognition is a long-standing social habit.\n",
    "- \"Areas outside the Third Ring Road don't count as Chengdu\" clearly demarcates a geographical range, defining which areas are considered the local core.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "These geographical boundary definitions, along with the identification habits of the author and those around them, collectively form a set of socially conventional regional cognition standards used to define who is local, thereby confirming the local identity difference between \"Chongzhou\" and \"Chengdu\".\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author endorses and implicitly expresses the use of long-standing socially conventional regional cognition (such as the Third Ring Road division and associated city identity) to define \"local people\" identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text aligns with RL1 because the author emphasizes using long-standing social conventional cognition and regional scope demarcation to judge and express the belonging and identity of \"local people\".\n",
    "\n",
    "Output: RL1\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 2 (RL2)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hugs, anyway, in my eyes, I only look at administrative divisions. If it belongs to Qingdao, then they are Qingdao people, regardless of whether it's Jiaozhou or Chengyang. In earlier years, because transportation was inconvenient, people felt they were far apart, that's all. Now, whether it's by subway or car, you can get there in a moment.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author explicitly states that they believe \"local people\" identity should be based on administrative divisions. That is, as long as an area belongs to the administrative region of Qingdao (including Jiaozhou, Chengyang), its residents are considered Qingdao people. This is presented as the standard for judging local identity. The author also mentions that improved transportation convenience has changed past perceptions of distance.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"I only look at administrative divisions,\" \"If it belongs to Qingdao, then they are Qingdao people,\" highlights administrative belonging as the defining standard.\n",
    "- Specific districts (Jiaozhou, Chengyang) are mentioned, indicating that members within these administrative boundaries are considered local.\n",
    "- \"Transportation was inconvenient,\" \"subway,\" \"car, you can get there in a moment,\" although describing functional livability, serve as background to explain how perceptions related to administrative importance have changed, not as a standard for local identity itself.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Administrative division is the fundamental standard the author uses to define \"local people\" identity. Transportation convenience is supplementary information that supports the shift in perception regarding local identity based on administrative boundaries.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author significantly endorses using administrative divisions as the standard for judging \"local people.\"\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text reflects a definition of local identity based on administrative legitimacy and belonging, which aligns with RL2.\n",
    "\n",
    "Output: RL2\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 3 (RL3)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"In Guangzhou, within three generations counts as a true Guangzhou person, within two generations is a new Guangzhou person, one generation of pioneers are Guangzhou immigrants, and those whose families haven't spoken Cantonese for three generations are Guangzhou people from other provinces (ancestors were 'lao' - outsiders) who came to Guangzhou.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author clearly expresses that family lineage (intergenerational heritage) is the standard for defining \"local people\" identity. They use different generational markers to classify identities such as \"true Guangzhou person,\" \"new Guangzhou person,\" \"Guangzhou immigrant,\" and \"Guangzhou people from other provinces,\" emphasizing the importance of family roots.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Within three generations,\" \"within two generations,\" \"one generation of pioneers\" are clearly definitions based on family historical rootedness and growth history.\n",
    "- \"Haven't spoken Cantonese for three generations\" implies cultural-linguistic recognition.\n",
    "- However, the core thrust of the argument is based on generational lines, emphasizing lineage, heritage, and intergenerational identity.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Family historical rootedness is the primary standard the author uses to strictly define Guangzhou local identity. Generational heritage determines \"true\" belonging. Although language is mentioned, it is more to describe cultural differences of specific generations rather than being the primary standard.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author endorses and explicitly expresses family historical rootedness (family generational heritage) as the core standard for defining local identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text primarily reflects a logic of local identity based on family historical rootedness, aligning with RL3.\n",
    "\n",
    "Output: RL3\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 4 (RL4)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I'm a Chengdu native, I think it's okay! To be honest, I just really can't stand some accents.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author identifies as a \"Chengdu native,\" indicating their local identity. Simultaneously, mentioning they \"can't stand some accents\" implies that language accent serves as a standard or boundary for distinguishing \"local people\" from \"non-local people.\"\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"I'm a Chengdu native\" indicates an identity based on being born or having long-term residence in the area.\n",
    "- \"Can't stand some accents\" pertains to cultural-linguistic recognition.\n",
    "- Accent acts as a distinguishing marker between locals and non-locals.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "The author, through their self-identified \"native\" status and sensitivity to accents, demonstrates cultural-linguistic recognition as a standard for judging locals versus non-locals, implying an endorsement or exclusion based on cultural-linguistic traits.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author implicitly endorses cultural-linguistic differences, such as accent, as a standard for defining local identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text aligns with the RL4 category, which is based on using language and cultural characteristics to identify local people.\n",
    "\n",
    "Output: RL4\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 5 (RL5)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"That's why I like Beichen, it's a transition from the old city to the new district. The streetscape isn't as dilapidated as the old city's, it's only a dozen minutes from the city center, has all the amenities, and it's so comfortable to live there.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author expresses fondness for the Beichen area, primarily due to its living convenience and environmental quality, such as street conditions, proximity to the city center, and available amenities, stating it's \"so comfortable to live there.\" This reflects the author's criteria for evaluating the quality of different local areas.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"The streetscape isn't as dilapidated as the old city's\" highlights differences in environmental quality.\n",
    "- \"Only a dozen minutes from the city center\" emphasizes transportation convenience.\n",
    "- \"Has all the amenities\" refers to functional livability.\n",
    "- \"Comfortable to live there\" reflects an overall positive assessment of the area's quality of life.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "These descriptions support the author's positive evaluation of Beichen as a high-quality local area. This implies that Beichen offers ideal local living conditions, showcasing the author's use of living convenience and environmental quality as standards for assessing the quality of local areas and their \"local value.\"\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author explicitly uses environmental quality and convenience of amenities as standards for measuring and choosing an ideal local residential area.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "The text aligns with the RL5 standard, based on functional livability and environmental quality cognition, i.e., using living comfort and the quality of amenities to evaluate the hierarchy and \"local value\" of areas within the locality.\n",
    "\n",
    "Output: RL5\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 6 (RL6)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"After all, not many families can afford one or two million to buy a house in a better environment and still within the second ring road. My parents have worked in Chengdu for so long, mostly within the first or second ring road, and friends are also nearby. Buying in the suburbs is definitely unrealistic; buying and renovating a house within the first or second ring road is the best solution.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author expresses how economic capacity and social networks influence the choice of property location. They believe that owning property within the second ring road, close to work and friends, is a more realistic and ideal living choice. This implicitly suggests that property location and economic status serve as indicators of \"local\" identity and criteria for evaluating regional desirability.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Buy a house in a better environment and still within the second ring road\" emphasizes property location and quality.\n",
    "- \"My parents have worked in Chengdu for so long,\" \"friends are also nearby\" reflect social connections and roots in the community.\n",
    "- \"Buying in the suburbs is definitely unrealistic\" indicates a distinction between \"good local areas\" and \"peripheral areas.\"\n",
    "- \"Buying and renovating a house within the first or second ring road is the best solution\" reflects a comprehensive consideration of economic conditions and living environment.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "The author implicitly links economic strength, existing social ties (distribution of relatives and friends), and ownership of property in a core area as important standards for judging the stability of local identity and the value of a region. This expresses an endorsement of property within the second ring road and the social rootedness it implies.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author implicitly endorses owning property in a core area (like within the second ring road) and having stable social connections as important standards for local identity and regional quality.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text primarily reflects the influence of social rootedness and economic status symbolism on the determination of local identity, aligning with RL6.\n",
    "\n",
    "Output: RL6\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 7 (RL7)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Licang and Huangdao are rural areas, with many farmers. The older generation doesn't consider them city people.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author mentions \"farmers\" as an occupational identity and implies that the older generation excludes farmers from their definition of \"city people.\" This indicates that occupational identity plays a role in defining local identity.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Farmers\" as a specific occupational identity.\n",
    "- \"The older generation doesn't consider them city people\" implies identity exclusion or definition based on occupation.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Occupational identity is actually used as a standard to distinguish \"city people\" from non-city people, carrying symbolic meaning.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author (by relaying the older generation's view without refuting it in this context of defining local distinctions) acknowledges occupational identity (farmer) as a criterion for distinguishing between locals and non-locals, or different social groups within the local context.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "Using \"farmer\" as an occupational identity to define local status aligns with the occupational symbolism standard, thus qualifying as RL7.\n",
    "\n",
    "Output: RL7\"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    },\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6926c09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d4bea44d64e8c953cf4a81e91112c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac8fe0ad02f4e668de2078e0ec0c519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e64b407ba146e18a82bbc10af30281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15601ef0929947bf960c0daae1b7949a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb99d35930b40dcb20823d23f499d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/83 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sample.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "all_outputs = []\n",
    "batch_size = 100\n",
    "# sampling_params = SamplingParams(temperature=0.6, top_p=0.95, top_k=20, min_p=0, max_tokens=8192)\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.8, top_k=20, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        ) + \"1. Understand the Author's Core Expressive Intent:\"\n",
    "\n",
    "        formatted_prompts_batch.append(formatted_prompt)\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48309bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Extracted label was empty after stripping wrappers for original text at index 28 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 65 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 69 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 83 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 110 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 111 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 119 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 137 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 154 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 161 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 168 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 239 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 242 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 245 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 251 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 272 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 338 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 416 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 465 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 467 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Successfully processed 483 model outputs.\n",
      "Results saved to Qwen3-235B-A22B_few_shot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text         RL_Types  \\\n",
      "0   ...              RL1   \n",
      "1  ...  RL1, RL4, RL7   \n",
      "2  ...              RL4   \n",
      "3  ...              RL4   \n",
      "4  ...              RL4   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0    \\nThe author expresses pride and optimism ab...  \n",
      "1    \\nThe author is sharing multiple personal ob...  \n",
      "2    \\nThe author identifies as from **Dujiangyan...  \n",
      "3    \\nThe author expresses frustration and disda...  \n",
      "4    \\nThe author is criticizing what they percei...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"\"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"results/{model_path.split('/')[-1]}_few_shot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67da22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  RL1\n",
       "1      RL1, RL4, RL7\n",
       "2                  RL4\n",
       "3                  RL4\n",
       "4                  RL4\n",
       "             ...       \n",
       "478                RL1\n",
       "479                RL3\n",
       "480                RL7\n",
       "481          RL1, RL2\n",
       "482                RL1\n",
       "Name: RL_Types, Length: 483, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['RL_Types']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80aa49",
   "metadata": {},
   "source": [
    "# No CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040483b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"## Multi-Label Analysis of \"Local\" Identity Definition Standards in Social Network Texts\n",
    "\n",
    "### 1. Task Objective\n",
    "\n",
    "Analyze the given social media text segment to identify the prominent standards that the **author themself** explicitly expresses agreement with, or **implicitly agrees with** through the subtext, for defining a **\"local person\" (or its synonyms)**. Based on the Recognition Logic (RL) framework in this manual, output all corresponding RL category labels. A text segment may correspond to **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local person\" identity. If the text merely discusses wealth, social status, quality of life, property advantages/disadvantages, job quality, etc., **without explicitly or strongly implying** that these are standards used to judge whether someone is a \"local person,\" then **do not annotate**.\n",
    "\n",
    "### 2. Core Principles\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core viewpoint, claim, or evaluation regarding the definition of \"local person\" identity as presented by the **speaker (i.e., the text author)**. Understanding **what the author intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of Recognition Logic:** The identified recognition logic elements are not just isolated features; understand the **functional role** they play in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** Actively perform contextual reasoning to understand the basis of legitimacy for \"local person\" identity or the evaluation criteria endorsed by the author behind their discourse.\n",
    "*   **Exclude Resisted Standards and Irrelevant Discussions:** For standards that the author explicitly expresses resistance to, denies, or merely describes as being used against them by others, **do not annotate**. For discussions not directly related to defining \"local person\" identity, **do not annotate**.\n",
    "\n",
    "### 3. Recognition Logic Framework\n",
    "\n",
    "**Uniform Sentence Template:**\n",
    "The author believes that people (or the author themself) should/often/can use the logic or standards represented by [Recognition Logic Type] to define who is/is not a 'local person', or to evaluate the quality/scope of a 'local' area.\n",
    "\n",
    "**Recognition Logic Type Definitions and Features:**\n",
    "\n",
    "#### Recognition Logic 1 (RL1): Vernacular Spatial Authority\n",
    "*   **Definition:** Shared, habitual, or historically sedimented local perceptions of intra-city spatial categories that the author endorses or describes. These perceptions are not based on official administrative boundaries but reflect collective emotional maps, used as cultural shorthand for assigning evaluative or symbolic labels.\n",
    "*   **Core Identifying Features:**\n",
    "    *   The author explicitly proposes or assumes a logic for classifying **which areas \"count\" or \"do not count\" as core local areas, or which areas have identity or cognitive differences** (e.g., \"Outside the Third Ring Road is not considered Chengdu\").\n",
    "    *   The author implies the status of a specific area within the \"local\" identity system by describing its **symbolic meaning, historical labels, or common societal views (collective emotional map)**.\n",
    "    *   The author discusses **the social recognition changes or current consensus on concepts like \"urban area scope,\" \"city boundaries,\" etc.**\n",
    "\n",
    "#### Recognition Logic 2 (RL2): Administrative Legitimacy\n",
    "*   **Definition:** Appeals to official jurisdiction, legal status, or administrative designation. Speakers in this category justify inclusion or exclusion based on hukou registration (a household registration system), district incorporation, or municipal redistricting.\n",
    "*   **Core Identifying Features:** Keywords include \"administrative division,\" \"incorporated into,\" \"belongs to,\" \"where is the hukou from,\" \"ID card prefix,\" etc., used as a basis for judging whether a person/place is administratively/legally \"local.\"\n",
    "\n",
    "#### Recognition Logic 3 (RL3): Family Rootedness (Family Historical Roots / Individual Growth History)\n",
    "*   **Definition:** The author endorses or cites the evaluation of local legitimacy based on the generational depth of family settlement. Claims in this category emphasize lineage, ancestry, or long-term familial ties to the area.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Emphasizes terms like \"**born and raised locally**,\" \"**generations**,\" \"**ancestors**,\" \"**parents' generation**,\" \"**within three generations**,\" \"**came since childhood/kindergarten**,\" etc., to prove someone is a \"genuine local\" or has formed the basis of a \"local person's\" identity.\n",
    "    *   Describes identity differences due to migration history (or lack thereof).\n",
    "\n",
    "#### Recognition Logic 4 (RL4): Linguistic-Cultural Recognition\n",
    "*   **Definition:** Relies on dialect, accent, or cultural linguistic habits as a boundary marker. Regional speech features are treated as proxies for insider status, and deviations often provoke mockery or mistrust. May also include identification with specific local cultural habits (e.g., customs, lifestyle).\n",
    "*   **Core Identifying Features:** Mentions \"speaking the local dialect,\" \"accent,\" \"cannot understand/stand certain accents,\" \"don't you understand our local rules,\" etc., as criteria for distinguishing insiders from outsiders, or judging if someone is \"one of us\" or possesses \"local attributes.\"\n",
    "\n",
    "#### Recognition Logic 5 (RL5): Functional Livability (Convenience of Living Functions and Environmental Quality Perception)\n",
    "*   **Definition:** The author endorses or cites the evaluation of urban areas in terms of their material infrastructure (e.g., transit, housing, education, or access to services), often to assert spatial superiority or desirability.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"subway,\" \"amenities,\" \"convenience,\" \"education,\" \"good greening,\" \"few people,\" \"streetscape,\" \"comfortable,\" etc., and **directly associates these with an evaluation of whether an area is \"good,\" \"livable,\" or \"worth living in.\"**\n",
    "    *   The author considers an area an ideal \"local\" living space due to its RL5 characteristics, or believes an area does not meet the standard of a \"good local\" area due to a lack of RL5 characteristics.\n",
    "\n",
    "#### Recognition Logic 6 (RL6): Social Embeddedness (Depth of Social Roots and Symbolism of Economic Status)\n",
    "*   **Definition:** The author endorses or cites judging whether someone is a local based on their integration into local social circles and possession of local fixed assets. This includes community resources (like dividends, familiarity with the community) and material or symbolic resources, such as (inherited) property.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"connections (renmai),\" \"dividends,\" \"old relationships,\" \"community influence,\" \"friends nearby,\" \"has several properties in the city center,\" \"impact of high/low housing prices on identity,\" \"spending one or two million to buy a house,\" etc., and **explicitly or implicitly links these to the \"stability, authenticity, hierarchy of local identity, or evaluation criteria for a region.\"**\n",
    "\n",
    "#### Recognition Logic 7 (RL7): Occupational Typification\n",
    "*   **Definition:** The author endorses or cites framing identity by associating certain districts with dominant professional groups, such as civil servants, migrant workers, or business owners, thereby invoking implicit hierarchies of class and worth.\n",
    "*   **Core Identifying Features:** Mentions specific occupations or types of people (e.g., \"farmers,\" \"those who farm,\" \"migrant workers\"), and **strongly associates them with the \"local attributes,\" resident composition, or social stratification of a specific area**, thereby defining identity or evaluating the area.\n",
    "\n",
    "### 5. Important Notes\n",
    "*   Constantly remind yourself that the annotation target is **standards that the author themself does not explicitly oppose and uses to define \"local person\" identity or evaluate a \"local\" area, and understand their function in the author's core argument.**\n",
    "*   Do not rely solely on keyword matching; deeply understand the logic, intent, and core viewpoint behind the author's discourse. **Follow the steps from Step 1 to Step 4 in 4. Annotation Procedure; do not skip steps.**\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they use these standards to define \"who is a local person\" or evaluate \"the quality/scope/distinction of a local area,\" then **do not annotate.**\n",
    "*   Output the result after the `Output: ` marker. **Stop immediately** after outputting the result; do not output any further content.\"\"\"\n",
    "    }\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bcfff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebce00d2ddb4cf488a5ec6a3a2f7007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67df17874cb4ff2b167a79a0cbb468e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f48bef7e594c82ba359720635fd08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/83 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sample.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "all_outputs = []\n",
    "batch_size = 200\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.8, top_k=20, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        )\n",
    "        formatted_prompts_batch.append(formatted_prompt + \"Output: \")\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd699d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Extracted label was empty after stripping wrappers for original text at index 39 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 255 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 298 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Warning: Extracted label was empty after stripping wrappers for original text at index 350 (using primary (Output:) marker).\n",
      "Problematic Raw Output (after marker):\n",
      "\n",
      "==============================\n",
      "Successfully processed 483 model outputs.\n",
      "Results saved to Qwen3-235B-A22B_no_cot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text  \\\n",
      "0   ...   \n",
      "1  ...   \n",
      "2  ...   \n",
      "3  ...   \n",
      "4  ...   \n",
      "\n",
      "                                           RL_Types  \\\n",
      "0  1. **RL1: Socially Conventional Territorial I...   \n",
      "1                                              3 4 1   \n",
      "2                                                3,4   \n",
      "3                                          RL4 RL3   \n",
      "4                                                  4   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0  Output: 1. **RL1: Socially Conventional Terri...  \n",
      "1                                      Output: 3 4 1  \n",
      "2                                        Output: 3,4  \n",
      "3                                 Output:  RL4 RL3  \n",
      "4                                          Output: 4  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"\"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "    model_full_output_text = \"Output: \" + model_full_output_text\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"results/{model_path.split('/')[-1]}_no_cot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365c0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1. **RL1: Socially Conventional Territorial I...\n",
       "1                                                  3 4 1\n",
       "2                                                    3,4\n",
       "3                                              RL4 RL3\n",
       "4                                                      4\n",
       "                             ...                        \n",
       "478                                                1 3 4\n",
       "479                                                    3\n",
       "480                                                    \n",
       "481    2  \\nRL2: Administrative Legitimacy  \\nRL1: ...\n",
       "482    \\n\\nThis sentence implies that *...\n",
       "Name: RL_Types, Length: 483, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['RL_Types']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copylookup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
