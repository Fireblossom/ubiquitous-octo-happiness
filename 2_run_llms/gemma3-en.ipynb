{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c57c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 19:18:30 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9c5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 19:19:10 [config.py:689] This model supports multiple tasks: {'classify', 'reward', 'embed', 'generate', 'score'}. Defaulting to 'generate'.\n",
      "INFO 05-19 19:19:10 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 05-19 19:19:13 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='google/gemma-3-27b-it', speculative_config=None, tokenizer='google/gemma-3-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=google/gemma-3-27b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-19 19:19:15 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8c52979250>\n",
      "INFO 05-19 19:19:16 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-19 19:19:16 [cuda.py:221] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 19:19:22 [gpu_model_runner.py:1276] Starting to load model google/gemma-3-27b-it...\n",
      "INFO 05-19 19:19:22 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]\n",
      "WARNING 05-19 19:19:23 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-19 19:19:24 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394c3e25c1d64bd8b4ca757a5d33e66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/12 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-19 19:19:32 [loader.py:458] Loading weights took 7.68 seconds\n",
      "INFO 05-19 19:19:32 [gpu_model_runner.py:1291] Model loading took 51.4482 GiB and 9.958507 seconds\n",
      "INFO 05-19 19:19:32 [gpu_model_runner.py:1560] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 64 image items of the maximum feature size.\n",
      "INFO 05-19 19:19:54 [backends.py:416] Using cache directory: /nfs/home/tanz/.cache/vllm/torch_compile_cache/12e98ecf6e/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-19 19:19:54 [backends.py:426] Dynamo bytecode transform time: 19.09 s\n",
      "INFO 05-19 19:19:55 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "INFO 05-19 19:20:22 [monitor.py:33] torch.compile takes 19.09 s in total\n",
      "INFO 05-19 19:20:25 [kv_cache_utils.py:634] GPU KV cache size: 62,096 tokens\n",
      "INFO 05-19 19:20:25 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 1.90x\n",
      "INFO 05-19 19:20:49 [gpu_model_runner.py:1626] Graph capturing finished in 24 secs, took 1.14 GiB\n",
      "INFO 05-19 19:20:49 [core.py:163] init engine (profile, create kv cache, warmup model) took 76.84 seconds\n",
      "INFO 05-19 19:20:49 [core_client.py:435] Core engine process 0 ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_path = \"google/gemma-3-27b-it\"\n",
    "llm = LLM(model_path, max_model_len=32768, dtype=torch.bfloat16, gpu_memory_utilization=0.99)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba3849",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6fdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"## Multi-Label Analysis of \"Local\" Identity Definition Standards in Social Network Texts\n",
    "\n",
    "### 1. Task Objective\n",
    "\n",
    "Analyze the given social media text segment to identify the prominent standards that the **author themself** explicitly expresses agreement with, or **implicitly agrees with** through the subtext, for defining a **\"local person\" (or its synonyms)**. Based on the Recognition Logic (RL) framework in this manual, output all corresponding RL category labels. A text segment may correspond to **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local person\" identity. If the text merely discusses wealth, social status, quality of life, property advantages/disadvantages, job quality, etc., **without explicitly or strongly implying** that these are standards used to judge whether someone is a \"local person,\" then **do not annotate**.\n",
    "\n",
    "### 2. Core Principles\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core viewpoint, claim, or evaluation regarding the definition of \"local person\" identity as presented by the **speaker (i.e., the text author)**. Understanding **what the author intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of Recognition Logic:** The identified recognition logic elements are not just isolated features; understand the **functional role** they play in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** Actively perform contextual reasoning to understand the basis of legitimacy for \"local person\" identity or the evaluation criteria endorsed by the author behind their discourse.\n",
    "*   **Exclude Resisted Standards and Irrelevant Discussions:** For standards that the author explicitly expresses resistance to, denies, or merely describes as being used against them by others, **do not annotate**. For discussions not directly related to defining \"local person\" identity, **do not annotate**.\n",
    "\n",
    "### 3. Recognition Logic Framework\n",
    "\n",
    "**Uniform Sentence Template:**\n",
    "The author believes that people (or the author themself) should/often/can use the logic or standards represented by [Recognition Logic Type] to define who is/is not a 'local person', or to evaluate the quality/scope of a 'local' area.\n",
    "\n",
    "**Recognition Logic Type Definitions and Features:**\n",
    "\n",
    "#### Recognition Logic 1 (RL1): Vernacular Spatial Authority\n",
    "*   **Definition:** Shared, habitual, or historically sedimented local perceptions of intra-city spatial categories that the author endorses or describes. These perceptions are not based on official administrative boundaries but reflect collective emotional maps, used as cultural shorthand for assigning evaluative or symbolic labels.\n",
    "*   **Core Identifying Features:**\n",
    "    *   The author explicitly proposes or assumes a logic for classifying **which areas \"count\" or \"do not count\" as core local areas, or which areas have identity or cognitive differences** (e.g., \"Outside the Third Ring Road is not considered Chengdu\").\n",
    "    *   The author implies the status of a specific area within the \"local\" identity system by describing its **symbolic meaning, historical labels, or common societal views (collective emotional map)**.\n",
    "    *   The author discusses **the social recognition changes or current consensus on concepts like \"urban area scope,\" \"city boundaries,\" etc.**\n",
    "\n",
    "#### Recognition Logic 2 (RL2): Administrative Legitimacy\n",
    "*   **Definition:** Appeals to official jurisdiction, legal status, or administrative designation. Speakers in this category justify inclusion or exclusion based on hukou registration (a household registration system), district incorporation, or municipal redistricting.\n",
    "*   **Core Identifying Features:** Keywords include \"administrative division,\" \"incorporated into,\" \"belongs to,\" \"where is the hukou from,\" \"ID card prefix,\" etc., used as a basis for judging whether a person/place is administratively/legally \"local.\"\n",
    "\n",
    "#### Recognition Logic 3 (RL3): Family Rootedness (Family Historical Roots / Individual Growth History)\n",
    "*   **Definition:** The author endorses or cites the evaluation of local legitimacy based on the generational depth of family settlement. Claims in this category emphasize lineage, ancestry, or long-term familial ties to the area.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Emphasizes terms like \"**born and raised locally**,\" \"**generations**,\" \"**ancestors**,\" \"**parents' generation**,\" \"**within three generations**,\" \"**came since childhood/kindergarten**,\" etc., to prove someone is a \"genuine local\" or has formed the basis of a \"local person's\" identity.\n",
    "    *   Describes identity differences due to migration history (or lack thereof).\n",
    "\n",
    "#### Recognition Logic 4 (RL4): Linguistic-Cultural Recognition\n",
    "*   **Definition:** Relies on dialect, accent, or cultural linguistic habits as a boundary marker. Regional speech features are treated as proxies for insider status, and deviations often provoke mockery or mistrust. May also include identification with specific local cultural habits (e.g., customs, lifestyle).\n",
    "*   **Core Identifying Features:** Mentions \"speaking the local dialect,\" \"accent,\" \"cannot understand/stand certain accents,\" \"don't you understand our local rules,\" etc., as criteria for distinguishing insiders from outsiders, or judging if someone is \"one of us\" or possesses \"local attributes.\"\n",
    "\n",
    "#### Recognition Logic 5 (RL5): Functional Livability (Convenience of Living Functions and Environmental Quality Perception)\n",
    "*   **Definition:** The author endorses or cites the evaluation of urban areas in terms of their material infrastructure (e.g., transit, housing, education, or access to services), often to assert spatial superiority or desirability.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"subway,\" \"amenities,\" \"convenience,\" \"education,\" \"good greening,\" \"few people,\" \"streetscape,\" \"comfortable,\" etc., and **directly associates these with an evaluation of whether an area is \"good,\" \"livable,\" or \"worth living in.\"**\n",
    "    *   The author considers an area an ideal \"local\" living space due to its RL5 characteristics, or believes an area does not meet the standard of a \"good local\" area due to a lack of RL5 characteristics.\n",
    "\n",
    "#### Recognition Logic 6 (RL6): Social Embeddedness (Depth of Social Roots and Symbolism of Economic Status)\n",
    "*   **Definition:** The author endorses or cites judging whether someone is a local based on their integration into local social circles and possession of local fixed assets. This includes community resources (like dividends, familiarity with the community) and material or symbolic resources, such as (inherited) property.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"connections (renmai),\" \"dividends,\" \"old relationships,\" \"community influence,\" \"friends nearby,\" \"has several properties in the city center,\" \"impact of high/low housing prices on identity,\" \"spending one or two million to buy a house,\" etc., and **explicitly or implicitly links these to the \"stability, authenticity, hierarchy of local identity, or evaluation criteria for a region.\"**\n",
    "\n",
    "#### Recognition Logic 7 (RL7): Occupational Typification\n",
    "*   **Definition:** The author endorses or cites framing identity by associating certain districts with dominant professional groups, such as civil servants, migrant workers, or business owners, thereby invoking implicit hierarchies of class and worth.\n",
    "*   **Core Identifying Features:** Mentions specific occupations or types of people (e.g., \"farmers,\" \"those who farm,\" \"migrant workers\"), and **strongly associates them with the \"local attributes,\" resident composition, or social stratification of a specific area**, thereby defining identity or evaluating the area.\n",
    "\n",
    "### 4. Annotation Procedure\n",
    "1.  **Step 1: Identify named entities mentioned in the text**\n",
    "    *   Read through the text and record the entities mentioned.\n",
    "2.  **Step 2: Match arguments to each named entity**\n",
    "    *   Read the text carefully and match the corresponding viewpoint statements to each mentioned entity.\n",
    "3.  **Step 3: Analyze the underlying recognition logic behind each viewpoint statement**\n",
    "    *   For each entity, analyze which recognition logic(s) the speaker's expressed viewpoint (if any) is based on. It can be multiple recognition logics.\n",
    "4.  **Step 4: Output the results**\n",
    "    *   Output all matched **one or more** recognition logic category labels [Recognition Logic N], separated by ``, `` (a comma followed by a space).\n",
    "\n",
    "### 5. Important Notes\n",
    "*   Constantly remind yourself that the annotation target is **standards that the author themself does not explicitly oppose and uses to define \"local person\" identity or evaluate a \"local\" area, and understand their function in the author's core argument.**\n",
    "*   Do not rely solely on keyword matching; deeply understand the logic, intent, and core viewpoint behind the author's discourse. **Follow the steps from Step 1 to Step 4 in 4. Annotation Procedure; do not skip steps.**\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they use these standards to define \"who is a local person\" or evaluate \"the quality/scope/distinction of a local area,\" then **do not annotate.**\n",
    "*   Output the result after the `Output: ` marker. **Stop immediately** after outputting the result; do not output any further content.\"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910dcf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbb41801e5047b0bc0930df2b6da8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/483 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../0_data_collection/dataset.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "all_outputs = []\n",
    "batch_size = 500\n",
    "sampling_params = SamplingParams(temperature=1.0, top_p=0.95, top_k=64, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            #enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        ) + \"**Step 1: Understand the Author's Core Expressive Intent**\\n \"\n",
    "        formatted_prompts_batch.append(formatted_prompt)\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832d36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 483 model outputs.\n",
      "Results saved to gemma-3-27b-it_zero_shot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text  \\\n",
      "0  热烈欢迎咱叙北第一带盐人 北门可不差，论三环外，东西三环可不一定有北三环好，再等火北弄好，那...   \n",
      "1  真的很多，我就是周边的，不管现实还是网上看的很多，他们天天说自己土著然后说我们弯脚杆，碰到过...   \n",
      "2  我是都江堰的，其他地方的我不敢说，但是我可是从小被成都口音嘲笑哦，我小时候去亲戚家耍过暑假，...   \n",
      "3  那我说都江堰话被笑的更多，我以前被介绍了个成都人，然后天天给我说他家以前二环以内的，说他家以...   \n",
      "4  那证明成都人的确不咋地，本来成都话口音离普通话语区就够偏了，很多怪音，他们还歧视本省的人，无...   \n",
      "\n",
      "                      RL_Types  \\\n",
      "0              RL1, RL2, RL5   \n",
      "1  **\\n\\nRL1, RL3, RL4, RL6   \n",
      "2                          RL4   \n",
      "3                           N/A   \n",
      "4                    RL1, RL4   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0  \\nThe author expresses enthusiasm and pride in...  \n",
      "1  \\nThe author expresses frustration with being ...  \n",
      "2  \\nThe author expresses a sense of being an out...  \n",
      "3  \\nThe author expresses frustration and dislike...  \n",
      "4  \\nThe author expresses a negative sentiment to...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"输出：\"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"输出：\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"./llm_outputs/{model_path.split('/')[-1]}_zero_shot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed41daf",
   "metadata": {},
   "source": [
    "# Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8794c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"## Multi-Label Analysis of \"Local\" Identity Definition Standards in Social Network Texts\n",
    "\n",
    "### 1. Task Objective\n",
    "\n",
    "Analyze the given social media text segment to identify the prominent standards that the **author themself** explicitly expresses agreement with, or **implicitly agrees with** through the subtext, for defining a **\"local person\" (or its synonyms)**. Based on the Recognition Logic (RL) framework in this manual, output all corresponding RL category labels. A text segment may correspond to **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local person\" identity. If the text merely discusses wealth, social status, quality of life, property advantages/disadvantages, job quality, etc., **without explicitly or strongly implying** that these are standards used to judge whether someone is a \"local person,\" then **do not annotate**.\n",
    "\n",
    "### 2. Core Principles\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core viewpoint, claim, or evaluation regarding the definition of \"local person\" identity as presented by the **speaker (i.e., the text author)**. Understanding **what the author intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of Recognition Logic:** The identified recognition logic elements are not just isolated features; understand the **functional role** they play in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** Actively perform contextual reasoning to understand the basis of legitimacy for \"local person\" identity or the evaluation criteria endorsed by the author behind their discourse.\n",
    "*   **Exclude Resisted Standards and Irrelevant Discussions:** For standards that the author explicitly expresses resistance to, denies, or merely describes as being used against them by others, **do not annotate**. For discussions not directly related to defining \"local person\" identity, **do not annotate**.\n",
    "\n",
    "### 3. Recognition Logic Framework\n",
    "\n",
    "**Uniform Sentence Template:**\n",
    "The author believes that people (or the author themself) should/often/can use the logic or standards represented by [Recognition Logic Type] to define who is/is not a 'local person', or to evaluate the quality/scope of a 'local' area.\n",
    "\n",
    "**Recognition Logic Type Definitions and Features:**\n",
    "\n",
    "#### Recognition Logic 1 (RL1): Vernacular Spatial Authority\n",
    "*   **Definition:** Shared, habitual, or historically sedimented local perceptions of intra-city spatial categories that the author endorses or describes. These perceptions are not based on official administrative boundaries but reflect collective emotional maps, used as cultural shorthand for assigning evaluative or symbolic labels.\n",
    "*   **Core Identifying Features:**\n",
    "    *   The author explicitly proposes or assumes a logic for classifying **which areas \"count\" or \"do not count\" as core local areas, or which areas have identity or cognitive differences** (e.g., \"Outside the Third Ring Road is not considered Chengdu\").\n",
    "    *   The author implies the status of a specific area within the \"local\" identity system by describing its **symbolic meaning, historical labels, or common societal views (collective emotional map)**.\n",
    "    *   The author discusses **the social recognition changes or current consensus on concepts like \"urban area scope,\" \"city boundaries,\" etc.**\n",
    "\n",
    "#### Recognition Logic 2 (RL2): Administrative Legitimacy\n",
    "*   **Definition:** Appeals to official jurisdiction, legal status, or administrative designation. Speakers in this category justify inclusion or exclusion based on hukou registration (a household registration system), district incorporation, or municipal redistricting.\n",
    "*   **Core Identifying Features:** Keywords include \"administrative division,\" \"incorporated into,\" \"belongs to,\" \"where is the hukou from,\" \"ID card prefix,\" etc., used as a basis for judging whether a person/place is administratively/legally \"local.\"\n",
    "\n",
    "#### Recognition Logic 3 (RL3): Family Rootedness (Family Historical Roots / Individual Growth History)\n",
    "*   **Definition:** The author endorses or cites the evaluation of local legitimacy based on the generational depth of family settlement. Claims in this category emphasize lineage, ancestry, or long-term familial ties to the area.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Emphasizes terms like \"**born and raised locally**,\" \"**generations**,\" \"**ancestors**,\" \"**parents' generation**,\" \"**within three generations**,\" \"**came since childhood/kindergarten**,\" etc., to prove someone is a \"genuine local\" or has formed the basis of a \"local person's\" identity.\n",
    "    *   Describes identity differences due to migration history (or lack thereof).\n",
    "\n",
    "#### Recognition Logic 4 (RL4): Linguistic-Cultural Recognition\n",
    "*   **Definition:** Relies on dialect, accent, or cultural linguistic habits as a boundary marker. Regional speech features are treated as proxies for insider status, and deviations often provoke mockery or mistrust. May also include identification with specific local cultural habits (e.g., customs, lifestyle).\n",
    "*   **Core Identifying Features:** Mentions \"speaking the local dialect,\" \"accent,\" \"cannot understand/stand certain accents,\" \"don't you understand our local rules,\" etc., as criteria for distinguishing insiders from outsiders, or judging if someone is \"one of us\" or possesses \"local attributes.\"\n",
    "\n",
    "#### Recognition Logic 5 (RL5): Functional Livability (Convenience of Living Functions and Environmental Quality Perception)\n",
    "*   **Definition:** The author endorses or cites the evaluation of urban areas in terms of their material infrastructure (e.g., transit, housing, education, or access to services), often to assert spatial superiority or desirability.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"subway,\" \"amenities,\" \"convenience,\" \"education,\" \"good greening,\" \"few people,\" \"streetscape,\" \"comfortable,\" etc., and **directly associates these with an evaluation of whether an area is \"good,\" \"livable,\" or \"worth living in.\"**\n",
    "    *   The author considers an area an ideal \"local\" living space due to its RL5 characteristics, or believes an area does not meet the standard of a \"good local\" area due to a lack of RL5 characteristics.\n",
    "\n",
    "#### Recognition Logic 6 (RL6): Social Embeddedness (Depth of Social Roots and Symbolism of Economic Status)\n",
    "*   **Definition:** The author endorses or cites judging whether someone is a local based on their integration into local social circles and possession of local fixed assets. This includes community resources (like dividends, familiarity with the community) and material or symbolic resources, such as (inherited) property.\n",
    "*   **Core Identifying Features:**\n",
    "    *   Mentions \"connections (renmai),\" \"dividends,\" \"old relationships,\" \"community influence,\" \"friends nearby,\" \"has several properties in the city center,\" \"impact of high/low housing prices on identity,\" \"spending one or two million to buy a house,\" etc., and **explicitly or implicitly links these to the \"stability, authenticity, hierarchy of local identity, or evaluation criteria for a region.\"**\n",
    "\n",
    "#### Recognition Logic 7 (RL7): Occupational Typification\n",
    "*   **Definition:** The author endorses or cites framing identity by associating certain districts with dominant professional groups, such as civil servants, migrant workers, or business owners, thereby invoking implicit hierarchies of class and worth.\n",
    "*   **Core Identifying Features:** Mentions specific occupations or types of people (e.g., \"farmers,\" \"those who farm,\" \"migrant workers\"), and **strongly associates them with the \"local attributes,\" resident composition, or social stratification of a specific area**, thereby defining identity or evaluating the area.\n",
    "\n",
    "### 4. Annotation Procedure\n",
    "1.  **Step 1: Identify named entities mentioned in the text**\n",
    "    *   Read through the text and record the entities mentioned.\n",
    "2.  **Step 2: Match arguments to each named entity**\n",
    "    *   Read the text carefully and match the corresponding viewpoint statements to each mentioned entity.\n",
    "3.  **Step 3: Analyze the underlying recognition logic behind each viewpoint statement**\n",
    "    *   For each entity, analyze which recognition logic(s) the speaker's expressed viewpoint (if any) is based on. It can be multiple recognition logics.\n",
    "4.  **Step 4: Output the results**\n",
    "    *   Output all matched **one or more** recognition logic category labels [Recognition Logic N], separated by ``, `` (a comma followed by a space).\n",
    "\n",
    "### 5. Important Notes\n",
    "*   Constantly remind yourself that the annotation target is **standards that the author themself does not explicitly oppose and uses to define \"local person\" identity or evaluate a \"local\" area, and understand their function in the author's core argument.**\n",
    "*   Do not rely solely on keyword matching; deeply understand the logic, intent, and core viewpoint behind the author's discourse. **Follow the steps from Step 1 to Step 4 in 4. Annotation Procedure; do not skip steps.**\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they use these standards to define \"who is a local person\" or evaluate \"the quality/scope/distinction of a local area,\" then **do not annotate.**\n",
    "*   Output the result after the `Output: ` marker. **Stop immediately** after outputting the result; do not output any further content.\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 1 (RL1)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Well, people from Chongzhou, when asked where they're from, they directly say Chongzhou, not Chengdu. What I've learned since I was young is that Chengdu people generally think areas outside the Third Ring Road don't count as Chengdu.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author wants to express that they and people around them, when identifying their \"local\" identity, will directly say \"Chongzhou\" and not \"Chengdu\"; furthermore, the author has been influenced by a long-standing social convention since childhood that Chengdu people generally believe areas outside the city's Third Ring Road are not considered part of the core \"Chengdu\" local area. This reflects a standard for defining \"local people\" based on geographical scope and social custom.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- People around the author identify their area as \"Chongzhou\", not \"Chengdu\", reflecting regional cognition and identity definition.\n",
    "- \"Learned since I was young\" (ear濡目染) indicates this cognition is a long-standing social habit.\n",
    "- \"Areas outside the Third Ring Road don't count as Chengdu\" clearly demarcates a geographical range, defining which areas are considered the local core.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "These geographical boundary definitions, along with the identification habits of the author and those around them, collectively form a set of socially conventional regional cognition standards used to define who is local, thereby confirming the local identity difference between \"Chongzhou\" and \"Chengdu\".\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author endorses and implicitly expresses the use of long-standing socially conventional regional cognition (such as the Third Ring Road division and associated city identity) to define \"local people\" identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text aligns with RL1 because the author emphasizes using long-standing social conventional cognition and regional scope demarcation to judge and express the belonging and identity of \"local people\".\n",
    "\n",
    "Output: RL1\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 2 (RL2)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hugs, anyway, in my eyes, I only look at administrative divisions. If it belongs to Qingdao, then they are Qingdao people, regardless of whether it's Jiaozhou or Chengyang. In earlier years, because transportation was inconvenient, people felt they were far apart, that's all. Now, whether it's by subway or car, you can get there in a moment.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author explicitly states that they believe \"local people\" identity should be based on administrative divisions. That is, as long as an area belongs to the administrative region of Qingdao (including Jiaozhou, Chengyang), its residents are considered Qingdao people. This is presented as the standard for judging local identity. The author also mentions that improved transportation convenience has changed past perceptions of distance.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"I only look at administrative divisions,\" \"If it belongs to Qingdao, then they are Qingdao people,\" highlights administrative belonging as the defining standard.\n",
    "- Specific districts (Jiaozhou, Chengyang) are mentioned, indicating that members within these administrative boundaries are considered local.\n",
    "- \"Transportation was inconvenient,\" \"subway,\" \"car, you can get there in a moment,\" although describing functional livability, serve as background to explain how perceptions related to administrative importance have changed, not as a standard for local identity itself.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Administrative division is the fundamental standard the author uses to define \"local people\" identity. Transportation convenience is supplementary information that supports the shift in perception regarding local identity based on administrative boundaries.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author significantly endorses using administrative divisions as the standard for judging \"local people.\"\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text reflects a definition of local identity based on administrative legitimacy and belonging, which aligns with RL2.\n",
    "\n",
    "Output: RL2\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 3 (RL3)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"In Guangzhou, within three generations counts as a true Guangzhou person, within two generations is a new Guangzhou person, one generation of pioneers are Guangzhou immigrants, and those whose families haven't spoken Cantonese for three generations are Guangzhou people from other provinces (ancestors were 'lao佬' - outsiders) who came to Guangzhou.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author clearly expresses that family lineage (intergenerational heritage) is the standard for defining \"local people\" identity. They use different generational markers to classify identities such as \"true Guangzhou person,\" \"new Guangzhou person,\" \"Guangzhou immigrant,\" and \"Guangzhou people from other provinces,\" emphasizing the importance of family roots.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Within three generations,\" \"within two generations,\" \"one generation of pioneers\" are clearly definitions based on family historical rootedness and growth history.\n",
    "- \"Haven't spoken Cantonese for three generations\" implies cultural-linguistic recognition.\n",
    "- However, the core thrust of the argument is based on generational lines, emphasizing lineage, heritage, and intergenerational identity.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Family historical rootedness is the primary standard the author uses to strictly define Guangzhou local identity. Generational heritage determines \"true\" belonging. Although language is mentioned, it is more to describe cultural differences of specific generations rather than being the primary standard.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author endorses and explicitly expresses family historical rootedness (family generational heritage) as the core standard for defining local identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text primarily reflects a logic of local identity based on family historical rootedness, aligning with RL3.\n",
    "\n",
    "Output: RL3\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 4 (RL4)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I'm a Chengdu native, I think it's okay! To be honest, I just really can't stand some accents.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author identifies as a \"Chengdu native,\" indicating their local identity. Simultaneously, mentioning they \"can't stand some accents\" implies that language accent serves as a standard or boundary for distinguishing \"local people\" from \"non-local people.\"\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"I'm a Chengdu native\" indicates an identity based on being born or having long-term residence in the area.\n",
    "- \"Can't stand some accents\" pertains to cultural-linguistic recognition.\n",
    "- Accent acts as a distinguishing marker between locals and non-locals.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "The author, through their self-identified \"native\" status and sensitivity to accents, demonstrates cultural-linguistic recognition as a standard for judging locals versus non-locals, implying an endorsement or exclusion based on cultural-linguistic traits.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author implicitly endorses cultural-linguistic differences, such as accent, as a standard for defining local identity.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text aligns with the RL4 category, which is based on using language and cultural characteristics to identify local people.\n",
    "\n",
    "Output: RL4\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 5 (RL5)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"That's why I like Beichen, it's a transition from the old city to the new district. The streetscape isn't as dilapidated as the old city's, it's only a dozen minutes from the city center, has all the amenities, and it's so comfortable to live there.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author expresses fondness for the Beichen area, primarily due to its living convenience and environmental quality, such as street conditions, proximity to the city center, and available amenities, stating it's \"so comfortable to live there.\" This reflects the author's criteria for evaluating the quality of different local areas.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"The streetscape isn't as dilapidated as the old city's\" highlights differences in environmental quality.\n",
    "- \"Only a dozen minutes from the city center\" emphasizes transportation convenience.\n",
    "- \"Has all the amenities\" refers to functional livability.\n",
    "- \"Comfortable to live there\" reflects an overall positive assessment of the area's quality of life.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "These descriptions support the author's positive evaluation of Beichen as a high-quality local area. This implies that Beichen offers ideal local living conditions, showcasing the author's use of living convenience and environmental quality as standards for assessing the quality of local areas and their \"local value.\"\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author explicitly uses environmental quality and convenience of amenities as standards for measuring and choosing an ideal local residential area.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "The text aligns with the RL5 standard, based on functional livability and environmental quality cognition, i.e., using living comfort and the quality of amenities to evaluate the hierarchy and \"local value\" of areas within the locality.\n",
    "\n",
    "Output: RL5\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 6 (RL6)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"After all, not many families can afford one or two million to buy a house in a better environment and still within the second ring road. My parents have worked in Chengdu for so long, mostly within the first or second ring road, and friends are also nearby. Buying in the suburbs is definitely unrealistic; buying and renovating a house within the first or second ring road is the best solution.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author expresses how economic capacity and social networks influence the choice of property location. They believe that owning property within the second ring road, close to work and friends, is a more realistic and ideal living choice. This implicitly suggests that property location and economic status serve as indicators of \"local\" identity and criteria for evaluating regional desirability.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Buy a house in a better environment and still within the second ring road\" emphasizes property location and quality.\n",
    "- \"My parents have worked in Chengdu for so long,\" \"friends are also nearby\" reflect social connections and roots in the community.\n",
    "- \"Buying in the suburbs is definitely unrealistic\" indicates a distinction between \"good local areas\" and \"peripheral areas.\"\n",
    "- \"Buying and renovating a house within the first or second ring road is the best solution\" reflects a comprehensive consideration of economic conditions and living environment.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "The author implicitly links economic strength, existing social ties (distribution of relatives and friends), and ownership of property in a core area as important standards for judging the stability of local identity and the value of a region. This expresses an endorsement of property within the second ring road and the social rootedness it implies.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author implicitly endorses owning property in a core area (like within the second ring road) and having stable social connections as important standards for local identity and regional quality.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "This text primarily reflects the influence of social rootedness and economic status symbolism on the determination of local identity, aligning with RL6.\n",
    "\n",
    "Output: RL6\"\"\"\n",
    "    },\n",
    "    { # FEW-SHOT EXAMPLE 7 (RL7)\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Licang and Huangdao are rural areas, with many farmers. The older generation doesn't consider them city people.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\"1. Understand the Author's Core Expressive Intent:\n",
    "The author mentions \"farmers\" as an occupational identity and implies that the older generation excludes farmers from their definition of \"city people.\" This indicates that occupational identity plays a role in defining local identity.\n",
    "\n",
    "2. Identify All Potential RL Elements:\n",
    "- \"Farmers\" as a specific occupational identity.\n",
    "- \"The older generation doesn't consider them city people\" implies identity exclusion or definition based on occupation.\n",
    "\n",
    "3. Analyze the Functional Role of RL Elements in the Author's Core Argument:\n",
    "Occupational identity is actually used as a standard to distinguish \"city people\" from non-city people, carrying symbolic meaning.\n",
    "\n",
    "4. Filter RL Criteria Related to the Core Argument and Endorsed by the Author:\n",
    "The author (by relaying the older generation's view without refuting it in this context of defining local distinctions) acknowledges occupational identity (farmer) as a criterion for distinguishing between locals and non-locals, or different social groups within the local context.\n",
    "\n",
    "5. Precisely Match RL Categories and Construct an Explanation:\n",
    "Using \"farmer\" as an occupational identity to define local status aligns with the occupational symbolism standard, thus qualifying as RL7.\n",
    "\n",
    "Output: RL7\"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    },\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6926c09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f06394fcb7d44059a78b881e157042f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/483 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../0_data_collection/dataset.csv')\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "all_outputs = []\n",
    "batch_size = 500\n",
    "sampling_params = SamplingParams(temperature=1.0, top_p=0.95, top_k=64, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        ) + \"1. Understand the Author's Core Expressive Intent:\"\n",
    "\n",
    "        formatted_prompts_batch.append(formatted_prompt)\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48309bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 483 model outputs.\n",
      "Results saved to gemma-3-27b-it_few_shot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text               RL_Types  \\\n",
      "0  热烈欢迎咱叙北第一带盐人 北门可不差，论三环外，东西三环可不一定有北三环好，再等火北弄好，那...                    RL1   \n",
      "1  真的很多，我就是周边的，不管现实还是网上看的很多，他们天天说自己土著然后说我们弯脚杆，碰到过...  RL1, RL4, RL5, RL6   \n",
      "2  我是都江堰的，其他地方的我不敢说，但是我可是从小被成都口音嘲笑哦，我小时候去亲戚家耍过暑假，...                    RL4   \n",
      "3  那我说都江堰话被笑的更多，我以前被介绍了个成都人，然后天天给我说他家以前二环以内的，说他家以...              RL3, RL4   \n",
      "4  那证明成都人的确不咋地，本来成都话口音离普通话语区就够偏了，很多怪音，他们还歧视本省的人，无...                    RL4   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0  \\nThe author warmly welcomes someone identifie...  \n",
      "1  \\nThe author recounts numerous experiences of ...  \n",
      "2  \\nThe author, identifying as from Dujiangyan, ...  \n",
      "3  \\nThe author expresses annoyance with someone ...  \n",
      "4  \\nThe author expresses strong negative feeling...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"输出：\"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"输出：\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"./llm_outputs/{model_path.split('/')[-1]}_few_shot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67da22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        RL1\n",
       "1      RL1, RL4, RL5, RL6\n",
       "2                        RL4\n",
       "3                  RL3, RL4\n",
       "4                        RL4\n",
       "                ...          \n",
       "478                RL1, RL3\n",
       "479                      RL1\n",
       "480                      RL1\n",
       "481                      RL2\n",
       "482                      RL1\n",
       "Name: RL_Types, Length: 483, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['RL_Types']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80aa49",
   "metadata": {},
   "source": [
    "# No CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040483b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(input_text: str):\n",
    "    return [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"\"\"# Multi-label Analysis of Criteria for Defining \"Local Identity\" in Social Media Text\n",
    "\n",
    "## 1. Task Objective\n",
    "\n",
    "Analyze the given social media text snippet and determine what significant criteria the **author themselves** explicitly endorse or **implicitly convey** within it, which are used to define \"**local people**\" (or synonyms). Based on the RL framework in this manual, output all corresponding RL category labels. A text may fit **one or more** RL categories.\n",
    "\n",
    "**Core Limitation:** This task **only focuses** on how the author defines \"local identity\". If the text merely discusses wealth, social status, quality of life, property merits/demerits, job quality, etc., and **does not explicitly or strongly imply** that these are used as criteria to judge whether someone is \"local\", then **do not annotate**.\n",
    "\n",
    "## 2. Core Principles\n",
    "\n",
    "*   **Focus on the Author's Core Argument:** Your judgment **must** be based on the core view, assertion, or evaluation regarding \"local identity\" definition presented by the **speaker (i.e., the text author)**. Understanding what the author **intends to say** is the primary task.\n",
    "*   **Analyze the Functional Role of RL:** The identified RL elements are not just isolated features; you must also understand their **functional role** in the author's construction of their core argument.\n",
    "*   **Actively Infer Context and Implicit Logic:** You need to actively infer context and understand the implicit logic behind the discourse, specifically the basis of legitimacy or evaluation standards for \"local identity\" that the author endorses.\n",
    "*   **Exclude Resisted Criteria and Irrelevant Discussions:** Criteria that the author explicitly resists or negates, or criteria merely described as being used by others against the author, **should not be annotated**. Discussions not directly related to defining \"local identity\" **should not be annotated**.\n",
    "\n",
    "## 3. RL (Symbolic Ranking Logic) Framework\n",
    "\n",
    "**Unified Sentence Template:**\n",
    "\"The author believes that people (or the author themselves) should/often/can use the logic or standards represented by [RL Type] to define who is/is not 'local', or to evaluate the quality/scope of a 'local' area.\"\n",
    "\n",
    "**RL Type Definitions and Characteristics:**\n",
    "\n",
    "*   **RL1: Socially Conventional Territorial Identity**\n",
    "    *   **Definition:** Regional cognition, scope definition, or mental maps endorsed or described by the author, based on long-accumulated social habits, emotions, and historical sediment. These cognitions are used to identify the identity affiliation of \"local people\", define the geographical or psychological boundaries of \"local\", or perform social segregation between regions.\n",
    "    *   **Core Identification Features:**\n",
    "        *   The author explicitly proposes or implicitly assumes a logic about **which areas \"count\" or \"don't count\" as the local core area, and where identity or cognitive differences exist between areas**.\n",
    "        *   The author hints at a specific area's status within the \"local\" identity system by describing its **symbolic meaning, historical labels, or generally accepted social views**.\n",
    "        *   The author discusses **changes in social recognition or current consensus regarding concepts like \"urban area boundaries\", \"city limits\", etc.**\n",
    "\n",
    "*   **RL2: Administrative Legitimacy**\n",
    "    *   **Definition:** \"Local people\" identity affiliation or regional scope definition endorsed or referenced by the author, based on legal factors such as administrative divisions, historical annexation, legal boundaries, and **household registration (hukou) affiliation**.\n",
    "    *   **Core Identification Features:** Keywords include \"划进\" (incorporated), \"归属\" (affiliated), \"户口是哪的\" (where one's hukou is from), \"身份证开头\" (ID card beginning number), used as the basis for judging whether someone/some place is \"local\" in an administrative or legal sense.\n",
    "\n",
    "*   **RL3: Family Historical Rootedness / Individual Growth History**\n",
    "    *   **Definition:** The foundation of \"local people\" identity endorsed or referenced by the author, based on **an individual's or family's birth and growth history, intergenerational heritage (grandparents', parents' generation), or early settlement experience** in the local area. In the context of immigrant cities, this can refer to an individual's localized growth history starting from childhood.\n",
    "    *   **Core Identification Features:**\n",
    "        *   Emphasis on \"**born and raised here**\", \"**generations**\", \"**grandparents' generation**\", \"**parents' generation**\", \"**came here since childhood/kindergarten**\", etc., to prove someone is a \"purebred local\" or has formed a basis for \"local identity\".\n",
    "        *   Description of identity differences resulting from migration history (or lack thereof).\n",
    "\n",
    "*   **RL4: Cultural-Linguistic Recognition**\n",
    "    *   **Definition:** Identification of whether someone **belongs to the \"local people\" group or possesses \"local\" characteristics**, endorsed or referenced by the author based on language, accent, and specific local cultural habits (such as customs, lifestyle).\n",
    "    *   **Core Identification Features:** Mentioning \"speaking the local dialect\", \"accent\", \"understanding our local rules\", etc., as criteria for judging insiders/outsiders, or determining if someone is \"one of us\" or possesses \"local attributes\".\n",
    "\n",
    "*   **RL5: Functional Livability & Environmental Quality Cognition**\n",
    "    *   **Definition:** Recognition of regional quality (good/bad) endorsed or referenced by the author, based on the area's functional livability (transportation, commercial facilities, public services, etc.) **or** environmental quality (e.g., greenery, low population density, good air quality, and other livability factors). This cognition is used as a standard for evaluating, choosing, or defining \"ideal local residential areas\" or defining a region's \"local value\".\n",
    "    *   **Core Identification Features:**\n",
    "        *   Mentioning \"Metro\", \"facilities\", \"convenient\", \"good greenery\", \"low population density\", etc., and **directly linking these to the evaluation of whether an area is \"good\"**.\n",
    "        *   The author considers a place an ideal \"local\" living space due to its RL5 characteristics, or considers it not meeting the standard of a \"good local\" area due to lacking RL5 characteristics.\n",
    "\n",
    "*   **RL6: Depth of Social Roots & Economic Standing**\n",
    "    *   **Definition:** Recognition of whether someone **counts as a \"rooted local\", a \"local with influence\", or the stability/authenticity of their local identity**, endorsed or referenced by the author based on the depth of social network, control over community resources (e.g., village/community dividends), connections/network, and **owning specific assets in core local areas (e.g., real estate) or having significant economic status** in the local area.\n",
    "    *   **Core Identification Features:**\n",
    "        *   Mentioning \"connections\", \"dividends\", \"old relationships\", \"community influence\", \"owning several properties in the city center\", \"impact of high/low housing prices on identity\", etc., and **explicitly or implicitly linking these to the \"stability, authenticity, hierarchy of local identity, or criteria for evaluating a region\"**.\n",
    "\n",
    "*   **RL7: Occupational Symbolism**\n",
    "    *   **Definition:** Distinction between \"**locals**\" and \"**outsiders**\" endorsed or referenced by the author, based on specific occupational identity or the type of occupation of the main residents in an area. This can also be used to judge whether a specific occupational group represents \"traditional locals\" or the characteristics of a certain \"local\" area.\n",
    "    *   **Core Identification Features:** Mentioning specific occupations and **strongly linking them to the \"local\" identity label or the \"local attributes\" of a specific area**, explicitly or implicitly.\n",
    "\n",
    "## 4. Notes\n",
    "\n",
    "*   Constantly remind yourself that the object of annotation is the criteria **not explicitly opposed by the author themselves, and used to define \"local identity\" or evaluate \"local\" areas, and understand their function in the author's core argument**.\n",
    "*   If the author is merely describing a phenomenon, expressing personal preference, or evaluating social status/wealth, without revealing that they themselves use these standards to define \"who is local\" or evaluate the \"quality/scope/distinction of local areas\", then **do not annotate**.\n",
    "*   Do not rely solely on keywords for mechanical matching; deeply understand the logic behind the author's words, their intent, and core viewpoint.\n",
    "*   Output the result after the `Output:` marker. **Stop immediately** after outputting the result, do not output any further content.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": input_text\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bcfff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb349db2598492cbd6b31b36abe808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%| | 0/483 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_outputs = []\n",
    "batch_size = 500\n",
    "sampling_params = SamplingParams(temperature=1.0, top_p=0.95, top_k=64, min_p=0, max_tokens=8192)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    current_batch_texts = texts[i:i + batch_size]\n",
    "    \n",
    "    if not current_batch_texts: # Should not happen if texts is not empty, but good practice\n",
    "        continue\n",
    "\n",
    "    formatted_prompts_batch = []\n",
    "    for p_text in current_batch_texts:\n",
    "        prompt_data = generate_prompt(p_text)\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            prompt_data,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n",
    "        )\n",
    "        formatted_prompts_batch.append(formatted_prompt + \"Output: \")\n",
    "    \n",
    "    # Generate outputs for the current batch\n",
    "    # The llm.generate call might show a progress bar if it's integrated with tqdm,\n",
    "    # which would reset for each batch. This is acceptable.\n",
    "    batch_outputs = llm.generate(formatted_prompts_batch, sampling_params)\n",
    "    all_outputs.extend(batch_outputs)\n",
    "\n",
    "outputs = all_outputs # The final list of all generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd699d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 483 model outputs.\n",
      "Results saved to gemma-3-27b-it_no_cot_en.csv\n",
      "\n",
      "First 5 rows of the parsed data:\n",
      "                                 Original_Input_Text  \\\n",
      "0  热烈欢迎咱叙北第一带盐人 北门可不差，论三环外，东西三环可不一定有北三环好，再等火北弄好，那...   \n",
      "1  真的很多，我就是周边的，不管现实还是网上看的很多，他们天天说自己土著然后说我们弯脚杆，碰到过...   \n",
      "2  我是都江堰的，其他地方的我不敢说，但是我可是从小被成都口音嘲笑哦，我小时候去亲戚家耍过暑假，...   \n",
      "3  那我说都江堰话被笑的更多，我以前被介绍了个成都人，然后天天给我说他家以前二环以内的，说他家以...   \n",
      "4  那证明成都人的确不咋地，本来成都话口音离普通话语区就够偏了，很多怪音，他们还歧视本省的人，无...   \n",
      "\n",
      "                                           RL_Types  \\\n",
      "0                                         RL1, RL5   \n",
      "1                       RL1, RL2, RL3, RL4, RL6   \n",
      "2              RL4: Cultural-Linguistic Recognition   \n",
      "3  RL4, RL6\\n\\n**Explanation:**\\n\\n*   **RL4 (...   \n",
      "4                                         RL4, RL1   \n",
      "\n",
      "                                    Raw_Model_Output  \n",
      "0                             Output: \\nRL1, RL5\\n  \n",
      "1           Output: \\nRL1, RL2, RL3, RL4, RL6\\n  \n",
      "2  Output: \\nRL4: Cultural-Linguistic Recognition\\n  \n",
      "3  Output: \\nRL4, RL6\\n\\n**Explanation:**\\n\\n* ...  \n",
      "4                             Output: \\nRL4, RL1\\n  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define English Output Markers ---\n",
    "# Primary regex for \"Output:\" (as specified in the prompt)\n",
    "# It looks for \"Output:\" followed by optional whitespace, and captures the rest.\n",
    "primary_output_marker_pattern_en = re.compile(r\"Output:\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Secondary regex for the step header \"Step 6: Output Result\"\n",
    "# This is a fallback if the primary marker isn't found.\n",
    "secondary_output_marker_pattern_en = re.compile(r\"Step 6: Output Result\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Tertiary regex for the step header \"**Step 6: Output**\" (with markdown bold)\n",
    "# This is another fallback.\n",
    "tertiary_output_marker_pattern_en = re.compile(r\"\\*\\*Step 6: Output\\*\\*\\s*(.*)\", re.DOTALL)\n",
    "\n",
    "# Regex for splitting by the simple \"Output:\" marker - used as the last fallback\n",
    "simple_output_marker_regex_en = r\"输出：\"\n",
    "# --- End of English Markers ---\n",
    "\n",
    "\n",
    "# Assuming all_outputs is defined from a previous cell, containing the model's full outputs\n",
    "# Assuming texts is defined from a previous cell, containing the original input texts\n",
    "# Assuming model_path is defined from a previous cell, used for naming the output file\n",
    "\n",
    "outputs = all_outputs\n",
    "texts = texts # Ensure texts is accessible if it's not global\n",
    "\n",
    "parsed_results_list = []\n",
    "\n",
    "for i, output_obj in enumerate(outputs):\n",
    "    original_text_from_dataset = texts[i]\n",
    "    # Assuming the structure of output_obj remains consistent (e.g., from vertexai response)\n",
    "    # Access the text content, handling potential structure variations if necessary\n",
    "    model_full_output_text = \"\"\n",
    "    try:\n",
    "        # Common ways to access text from different model APIs\n",
    "        if hasattr(output_obj, 'text'): # e.g., some older simple text responses\n",
    "             model_full_output_text = output_obj.text\n",
    "        elif hasattr(output_obj, 'content'): # e.g., some newer structures\n",
    "             model_full_output_text = output_obj.content\n",
    "        elif hasattr(output_obj, 'outputs') and output_obj.outputs and hasattr(output_obj.outputs[0], 'text'): # e.g., vertexai list of outputs\n",
    "             model_full_output_text = output_obj.outputs[0].text\n",
    "        else:\n",
    "             # Fallback or raise error if text cannot be found\n",
    "             print(f\"Warning: Could not find text content in output_obj structure for index {i}. Output object: {output_obj}\")\n",
    "             model_full_output_text = str(output_obj) # Use string representation as a last resort\n",
    "             # Consider adding a specific error type or logging here\n",
    "    except Exception as e:\n",
    "         print(f\"Error accessing text content for index {i}: {e}\")\n",
    "         model_full_output_text = str(output_obj) # Use string representation on error\n",
    "\n",
    "    model_full_output_text = \"Output: \" + model_full_output_text\n",
    "    # Initialize a dictionary to store data for the current item\n",
    "    current_parsed_item = {\n",
    "        \"Original_Input_Text\": original_text_from_dataset,\n",
    "        \"RL_Types\": \"PARSE_ERROR_NO_MARKER\", # Default if marker not found or parsing fails\n",
    "        \"Raw_Model_Output\": model_full_output_text # Store the raw model output for debugging\n",
    "    }\n",
    "\n",
    "    extracted_label_part = None\n",
    "    used_marker_type = None # To log which marker was successful\n",
    "\n",
    "    # Try to find the primary English output marker first (\"Output:\")\n",
    "    match_primary = primary_output_marker_pattern_en.search(model_full_output_text)\n",
    "    if match_primary:\n",
    "        extracted_label_part = match_primary.group(1).strip()\n",
    "        used_marker_type = \"primary (Output:)\"\n",
    "    else:\n",
    "        # If primary marker is not found, try the secondary English marker (step-based \"Step 6: Output Result\")\n",
    "        match_secondary = secondary_output_marker_pattern_en.search(model_full_output_text)\n",
    "        if match_secondary:\n",
    "            extracted_label_part = match_secondary.group(1).strip()\n",
    "            used_marker_type = \"secondary (Step 6: Output Result)\"\n",
    "        else:\n",
    "            # If secondary marker is not found, try the tertiary English marker (step-based \"**Step 6: Output**\")\n",
    "            match_tertiary = tertiary_output_marker_pattern_en.search(model_full_output_text)\n",
    "            if match_tertiary:\n",
    "                extracted_label_part = match_tertiary.group(1).strip()\n",
    "                used_marker_type = \"tertiary (**Step 6: Output**)\"\n",
    "            else:\n",
    "                # If tertiary marker is not found, try the simple plain \"输出：\" marker.\n",
    "                # We split by the marker and take the content after the *last* occurrence.\n",
    "                parts = re.split(simple_output_marker_regex_en, model_full_output_text)\n",
    "                if len(parts) > 1: # Marker was found\n",
    "                    extracted_label_part = parts[-1].strip()\n",
    "                    used_marker_type = f\"simple (plain '{simple_output_marker_regex_en}' marker)\"\n",
    "\n",
    "    if extracted_label_part is not None:\n",
    "        label = \"\"\n",
    "        # Attempt to clean the extracted part to get the pure label\n",
    "        # Case 1: Markdown code block like ```\\nLABEL\\n```\n",
    "        if extracted_label_part.startswith(\"```\\n\") and extracted_label_part.endswith(\"\\n```\"):\n",
    "            label = extracted_label_part[len(\"```\\n\") : -len(\"\\n```\")].strip()\n",
    "        # Case 2: Backticks like `LABEL`\n",
    "        elif extracted_label_part.startswith(\"`\") and extracted_label_part.endswith(\"`\"):\n",
    "            label = extracted_label_part[1:-1].strip()\n",
    "        # Case 3: No special formatting, just the text (it might be the label itself)\n",
    "        else:\n",
    "            label = extracted_label_part.strip()\n",
    "\n",
    "        # Check if the label is empty after stripping wrappers or is the explicit \"N/A\" output\n",
    "        if not label or label == \"N/A\":\n",
    "            current_parsed_item[\"RL_Types\"] = \"N/A\" # Consistent representation for no labels\n",
    "            if not label: # Log if it was empty due to stripping, not if it was explicitly \"N/A\"\n",
    "                 print(f\"Warning: Extracted label was empty after stripping wrappers for original text at index {i} (using {used_marker_type} marker).\")\n",
    "                 print(f\"Problematic Raw Output (after marker):\\n{extracted_label_part}\\n\" + \"=\"*30)\n",
    "        else:\n",
    "            current_parsed_item[\"RL_Types\"] = label\n",
    "\n",
    "    else:\n",
    "        # Log a warning if none of the English output markers are found\n",
    "        print(f\"Warning: Could not find any of the expected English markers: primary ('{primary_output_marker_pattern_en.pattern}'), secondary ('{secondary_output_marker_pattern_en.pattern}'), tertiary ('{tertiary_output_marker_pattern_en.pattern}'), or simple plain ('{simple_output_marker_regex_en}') in model output for original text at index {i}.\")\n",
    "        print(f\"Problematic Raw Output:\\n{model_full_output_text}\\n\" + \"=\"*30)\n",
    "        # RL_Types remains \"PARSE_ERROR_NO_MARKER\" as set during initialization\n",
    "\n",
    "    parsed_results_list.append(current_parsed_item)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of parsed dictionaries\n",
    "results_df = pd.DataFrame(parsed_results_list)\n",
    "\n",
    "# Define the output CSV filename - you might want to add something like \"_en\"\n",
    "# Assuming model_path is defined in a previous cell.\n",
    "output_csv_filename = f\"./llm_outputs/{model_path.split('/')[-1]}_no_cot_en.csv\" # Added _en\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(output_csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Successfully processed {len(parsed_results_list)} model outputs.\")\n",
    "print(f\"Results saved to {output_csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame as a quick check\n",
    "print(\"\\nFirst 5 rows of the parsed data:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             RL1, RL5\n",
       "1                           RL1, RL2, RL3, RL4, RL6\n",
       "2                  RL4: Cultural-Linguistic Recognition\n",
       "3      RL4, RL6\\n\\n**Explanation:**\\n\\n*   **RL4 (...\n",
       "4                                             RL4, RL1\n",
       "                             ...                        \n",
       "478                                     RL1, RL3, RL6\n",
       "479                                           RL3, RL1\n",
       "480                                           RL1, RL4\n",
       "481                                           RL1, RL2\n",
       "482                                           RL1, RL3\n",
       "Name: RL_Types, Length: 483, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['RL_Types']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
